METADATA AS ZONES AND FIELDS

1.1 ) Description :
-> As described in detail in the README, we used the zone and field data from documents like court name and date posted to tweak the cosine similarity scores for the documents.
-> This metadata fields based ranking can be turned on by setting the variable zones_metadata_switch to True in search.py file

1.2 ) Result Statistics :
Q1.TXT 
q1.txt performance with metadata ON =>
Total correct documents to be retrieved = 3
Total correct documents retrieved = 3
Precision = 0.000248015873016
Recall = 1.0
The positions at which the correct documents were retrieved =
600
3792
5419
q1.txt performance with metadata OFF =>
Total correct documents to be retrieved = 3
Total correct documents retrieved = 3
Precision = 0.000248015873016
Recall = 1.0
The positions at which the correct documents were retrieved =
243
3789
4510

Q2.TXT 
q2.txt performance with metadata ON =>
Total correct documents to be retrieved = 2
Total correct documents retrieved = 2
Precision = 0.000182448458311
Recall = 1.0
The positions at which the correct documents were retrieved =
35
52
q2.txt performance with metadata OFF => 
Total correct documents to be retrieved = 2
Total correct documents retrieved = 2
Precision = 0.000182448458311
Recall = 1.0
The positions at which the correct documents were retrieved =
1
93

Q3.TXT 
q3.txt performance with metadata ON =>
Total correct documents to be retrieved = 3
Total correct documents retrieved = 3
Precision = 0.000361969111969
Recall = 1.0
The positions at which the correct documents were retrieved =
0
1
3
q3.txt performance with metadata OFF =>
Total correct documents to be retrieved = 3
Total correct documents retrieved = 3
Precision = 0.000361969111969
Recall = 1.0
The positions at which the correct documents were retrieved =
0
1
3

1.3) Observations:
From the outputs for q1.txt with and and without metadata field based reordering, we observer that while precision and recall remain the same as expected, the positions at which the correct documents are retrieved in our ordering becomes worse when we apply the metadata ordering. The first correct result is obtained at 600th position in the output list when using metadata instead of 243th position when not using metadata. 
Similarly in output for q2.txt, the first correct results position slips from 1 to 35 upon using the metadata based reordering. There is no change in position of correct outputs for q3.txt.

1.4) Conclusion
Thus we can conclude that metadata based reordering makes the output worse in terms of pushing the correct document ids further down in the output of the ranked retrieval ordering.
Thus using metadata based reordering harms the results of our system.






PSEUDO RELEVANCE FEEDBACK : ROCCHIO FORMULA

2.1) Description :
-> For freetext retrieval, we do a round of pseudo relevance feedback assuming the top 1% of the initially retrieved documents are relevant. We then use Rocchio's formula to generate the expanded query, and then perform another round of cosine similarity computation with this new expanded query to generate the final list of ranked retrieval documents.

2.2) Result Statistics :
Q1.TXT 
q1.txt performance with rocchio ON =>
Total correct documents to be retrieved = 3
Total correct documents retrieved = 3
Precision = 0.000248015873016
Recall = 1.0
The positions at which the correct documents were retrieved =
242
3646
4510
q1.txt performance with rocchio OFF =>
Total correct documents to be retrieved = 3
Total correct documents retrieved = 3
Precision = 0.000248015873016
Recall = 1.0
The positions at which the correct documents were retrieved =
243
3789
4510

Q2.TXT 
q2.txt performance with rocchio ON =>
Total correct documents to be retrieved = 2
Total correct documents retrieved = 2
Precision = 0.000182448458311
Recall = 1.0
The positions at which the correct documents were retrieved =
1
94
q2.txt performance with rocchio OFF => 
Total correct documents to be retrieved = 2
Total correct documents retrieved = 2
Precision = 0.000182448458311
Recall = 1.0
The positions at which the correct documents were retrieved =
1
93

Q3.TXT 
q3.txt performance with rocchio ON =>
Total correct documents to be retrieved = 3
Total correct documents retrieved = 3
Precision = 0.000361969111969
Recall = 1.0
The positions at which the correct documents were retrieved =
0
1
3
q3.txt performance with rocchio OFF =>
Total correct documents to be retrieved = 3
Total correct documents retrieved = 3
Precision = 0.000361969111969
Recall = 1.0
The positions at which the correct documents were retrieved =
0
1
3

2.3) Observations:
From the outputs for q1.txt, we can observe that precision and recall remain the same whether we use the rochio based pseudo relevance feedback or not. We can also observe that while positions for the first two correctly retrieved document in the output is marginally improved from 243rd to 242nd position and from 3789th to 3646th position respectively, and the position of third correctly retrieved document remained the same at 4510th position. 
Similarly, in q2.txt the precision and recall remains same in either case but the position of the second correctly retrieved document drops slightly from 93rd to 94th position.
In q3.txt, the positions of the correctly retrieved documents remains the same whether we use the rochio based pseudo relevance feedback or not.

2.4) Conclusion
Thus we can conclude that rocchio base pseudo relevance feedback leads to marginal improvements in some cases while marginal decline in other cases, in the output of the ranked retrieval based ordering of documents. Thus using rocchio base pseudo relevance feedback does not lead to significant improvement as a query expansion technique.



SYNONYMS : WORDNET-QUERY EXPANSIONS





SYNONYMS : THESAURUS
